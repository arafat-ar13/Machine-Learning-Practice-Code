{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, RegexpParser\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> This is our text. Edit this text to see different kinds of chunks </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"This Kingdom is ruled by our Queen. As it have for thousands of years. \n",
    "No mortal enemy shall stand on our land and use force to rule. We, the Queen's men, are as humble as the mankind has ever seen and our shiny swords will cut through our enemies hearts almost certainly. \n",
    "All hail Queen Taylor.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenized = sent_tokenize(text)\n",
    "\n",
    "lemmatize = WordNetLemmatizer()\n",
    "lemmatized = [lemmatize.lemmatize(word) for word in sent_tokenized]\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stemmed = [ps.stem(word) for word in lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "\n",
    "for word in stemmed:\n",
    "    if word in stopwords:\n",
    "        stemmed.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenized = [word_tokenize(word) for word in stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagged = [pos_tag(word) for word in word_tokenized]\n",
    "pos_tagged = [word for inner_word in pos_tagged for word in inner_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking\n",
    "Till this far we have tokenized the text by sentence and also word level precision. And those words have been stemmed, lemmatized and PoS Tagged.\n",
    "Now we will take a look at **chunking**. This is a sort of sentence analysis where we chunk or group together similar or related senteces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> A really good and thorough video from <a href=\"https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ\">Sentdex</a> explains the process of chunking in an\n",
    "outstanding manner. </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/imPpT2Qo2sk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/imPpT2Qo2sk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_chunk = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "np_chunk_parser = RegexpParser(np_chunk)\n",
    "np_chunked = np_chunk_parser.parse(pos_tagged)\n",
    "\n",
    "np_chunked.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_chunk = \"VP: {<DT>?<JJ>*<NN><VB.*><RB.?>?}\"\n",
    "vp_chunk_parser = RegexpParser(vp_chunk)\n",
    "vp_chunked = vp_chunk_parser.parse(pos_tagged)\n",
    "\n",
    "vp_chunked.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
